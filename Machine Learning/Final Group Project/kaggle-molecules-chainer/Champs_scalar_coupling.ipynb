{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import gc\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avglinsky\\Miniconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:568: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "train_dtypes = {\n",
    "    'molecule_name': 'category',\n",
    "    'atom_index_0': 'int8',\n",
    "    'atom_index_1': 'int8',\n",
    "    'type': 'category',\n",
    "    'scalar_coupling_constant': 'float32'\n",
    "}\n",
    "structures_dtypes = {\n",
    "    'molecule_name': 'category',\n",
    "    'atom_index': 'int8',\n",
    "    'atom': 'category',\n",
    "    'x': 'float32',\n",
    "    'y': 'float32',\n",
    "    'z': 'float32'\n",
    "}\n",
    "train_csv = pd.read_csv(f'dataset/train.csv', index_col='id', dtype=train_dtypes)\n",
    "train_csv['molecule_index'] = train_csv.molecule_name.str.replace('dsgdb9nsd_', '').astype('int32')\n",
    "train_csv = train_csv[['molecule_index', 'atom_index_0', 'atom_index_1', 'type', 'scalar_coupling_constant']]\n",
    "test_csv = pd.read_csv(f'dataset/test.csv', index_col='id', dtype=train_dtypes)\n",
    "test_csv['molecule_index'] = test_csv['molecule_name'].str.replace('dsgdb9nsd_', '').astype('int32')\n",
    "test_csv = test_csv[['molecule_index', 'atom_index_0', 'atom_index_1', 'type']]\n",
    "submission_csv = pd.read_csv(f'dataset/sample_submission.csv', index_col='id')\n",
    "ATOMIC_NUMBERS = {\n",
    "    'H': 1,\n",
    "    'C': 6,\n",
    "    'N': 7,\n",
    "    'O': 8,\n",
    "    'F': 9\n",
    "}\n",
    "structures_csv = pd.read_csv(f'dataset/structures.csv', dtype=structures_dtypes)\n",
    "structures_csv['molecule_index'] = structures_csv.molecule_name.str.replace('dsgdb9nsd_', '').astype('int32')\n",
    "structures_csv = structures_csv[['molecule_index', 'atom_index', 'atom', 'x', 'y', 'z']]\n",
    "structures_csv['atom'] = structures_csv['atom'].replace(ATOMIC_NUMBERS).astype('int8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extend the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_type_dataframes(base, structures, coupling_type):\n",
    "    base = base[base['type'] == coupling_type].drop('type', axis=1).copy()\n",
    "    base = base.reset_index()\n",
    "    base['id'] = base['id'].astype('int32')\n",
    "    structures = structures[structures['molecule_index'].isin(base['molecule_index'])]\n",
    "    return base, structures\n",
    "\n",
    "def add_coordinates(base, structures, index):\n",
    "    df = pd.merge(base, structures, how='inner',\n",
    "                  left_on=['molecule_index', f'atom_index_{index}'],\n",
    "                  right_on=['molecule_index', 'atom_index']).drop(['atom_index'], axis=1)\n",
    "    df = df.rename(columns={\n",
    "        'atom': f'atom_{index}',\n",
    "        'x': f'x_{index}',\n",
    "        'y': f'y_{index}',\n",
    "        'z': f'z_{index}'\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def add_atoms(base, atoms):\n",
    "    df = pd.merge(base, atoms, how='inner',\n",
    "                  on=['molecule_index', 'atom_index_0', 'atom_index_1'])\n",
    "    return df\n",
    "\n",
    "def merge_all_atoms(base, structures):\n",
    "    df = pd.merge(base, structures, how='left',\n",
    "                  left_on=['molecule_index'],\n",
    "                  right_on=['molecule_index'])\n",
    "    df = df[(df.atom_index_0 != df.atom_index) & (df.atom_index_1 != df.atom_index)]\n",
    "    return df\n",
    "\n",
    "def add_center(df):\n",
    "    df['x_c'] = ((df['x_1'] + df['x_0']) * np.float32(0.5))\n",
    "    df['y_c'] = ((df['y_1'] + df['y_0']) * np.float32(0.5))\n",
    "    df['z_c'] = ((df['z_1'] + df['z_0']) * np.float32(0.5))\n",
    "\n",
    "def add_distance_to_center(df):\n",
    "    df['d_c'] = ((\n",
    "        (df['x_c'] - df['x'])**np.float32(2) +\n",
    "        (df['y_c'] - df['y'])**np.float32(2) + \n",
    "        (df['z_c'] - df['z'])**np.float32(2)\n",
    "    )**np.float32(0.5))\n",
    "\n",
    "def add_distance_between(df, suffix1, suffix2):\n",
    "    df[f'd_{suffix1}_{suffix2}'] = ((\n",
    "        (df[f'x_{suffix1}'] - df[f'x_{suffix2}'])**np.float32(2) +\n",
    "        (df[f'y_{suffix1}'] - df[f'y_{suffix2}'])**np.float32(2) + \n",
    "        (df[f'z_{suffix1}'] - df[f'z_{suffix2}'])**np.float32(2)\n",
    "    )**np.float32(0.5))\n",
    "    \n",
    "def add_distances(df):\n",
    "    n_atoms = 1 + max([int(c.split('_')[1]) for c in df.columns if c.startswith('x_')])\n",
    "    \n",
    "    for i in range(1, n_atoms):\n",
    "        for vi in range(min(4, i)):\n",
    "            add_distance_between(df, i, vi)\n",
    "            \n",
    "def add_n_atoms(base, structures):\n",
    "    dfs = structures['molecule_index'].value_counts().rename('n_atoms').to_frame()\n",
    "    return pd.merge(base, dfs, left_on='molecule_index', right_index=True)\n",
    "\n",
    "def build_couple_dataframe(some_csv, structures_csv, coupling_type, n_atoms=10):\n",
    "    base, structures = build_type_dataframes(some_csv, structures_csv, coupling_type)\n",
    "    base = add_coordinates(base, structures, 0)\n",
    "    base = add_coordinates(base, structures, 1)\n",
    "    \n",
    "    base = base.drop(['atom_0', 'atom_1'], axis=1)\n",
    "    atoms = base.drop('id', axis=1).copy()\n",
    "    if 'scalar_coupling_constant' in some_csv:\n",
    "        atoms = atoms.drop(['scalar_coupling_constant'], axis=1)\n",
    "        \n",
    "    add_center(atoms)\n",
    "    atoms = atoms.drop(['x_0', 'y_0', 'z_0', 'x_1', 'y_1', 'z_1'], axis=1)\n",
    "\n",
    "    atoms = merge_all_atoms(atoms, structures)\n",
    "    \n",
    "    add_distance_to_center(atoms)\n",
    "    \n",
    "    atoms = atoms.drop(['x_c', 'y_c', 'z_c', 'atom_index'], axis=1)\n",
    "    atoms.sort_values(['molecule_index', 'atom_index_0', 'atom_index_1', 'd_c'], inplace=True)\n",
    "    atom_groups = atoms.groupby(['molecule_index', 'atom_index_0', 'atom_index_1'])\n",
    "    atoms['num'] = atom_groups.cumcount() + 2\n",
    "    atoms = atoms.drop(['d_c'], axis=1)\n",
    "    atoms = atoms[atoms['num'] < n_atoms]\n",
    "\n",
    "    atoms = atoms.set_index(['molecule_index', 'atom_index_0', 'atom_index_1', 'num']).unstack()\n",
    "    atoms.columns = [f'{col[0]}_{col[1]}' for col in atoms.columns]\n",
    "    atoms = atoms.reset_index()\n",
    "    \n",
    "    # downcast back to int8\n",
    "    for col in atoms.columns:\n",
    "        if col.startswith('atom_'):\n",
    "            atoms[col] = atoms[col].fillna(0).astype('int8')\n",
    "            \n",
    "    atoms['molecule_index'] = atoms['molecule_index'].astype('int32')\n",
    "    \n",
    "    full = add_atoms(base, atoms)\n",
    "    add_distances(full)\n",
    "    \n",
    "    full.sort_values('id', inplace=True)\n",
    "    \n",
    "    return full\n",
    "\n",
    "def take_n_atoms(df, n_atoms, four_start=4):\n",
    "    labels = []\n",
    "    for i in range(2, n_atoms):\n",
    "        label = f'atom_{i}'\n",
    "        labels.append(label)\n",
    "\n",
    "    for i in range(n_atoms):\n",
    "        num = min(i, 4) if i < four_start else 4\n",
    "        for j in range(num):\n",
    "            labels.append(f'd_{i}_{j}')\n",
    "    if 'scalar_coupling_constant' in df:\n",
    "        labels.append('scalar_coupling_constant')\n",
    "    return df[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = build_couple_dataframe(train_csv, structures_csv, '1JHN', n_atoms=10)\n",
    "df = take_n_atoms(full, 7).fillna(0)\n",
    "X_data = df.drop(['scalar_coupling_constant'], axis=1).values.astype('float32')\n",
    "y_data = df['scalar_coupling_constant'].values.astype('float32')\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.2, random_state=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGB_PARAMS = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.2,\n",
    "    'num_leaves': 128,\n",
    "    'min_child_samples': 79,\n",
    "    'max_depth': 9,\n",
    "    'subsample_freq': 1,\n",
    "    'subsample': 0.9,\n",
    "    'bagging_seed': 20,\n",
    "    'reg_alpha': 0.2,\n",
    "    'reg_lambda': 0.3,\n",
    "    'colsample_bytree': 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 0.430851\tvalid_1's l1: 0.535862\n",
      "[200]\ttraining's l1: 0.355222\tvalid_1's l1: 0.485171\n",
      "[300]\ttraining's l1: 0.306765\tvalid_1's l1: 0.456667\n",
      "[400]\ttraining's l1: 0.272551\tvalid_1's l1: 0.441111\n",
      "[500]\ttraining's l1: 0.246132\tvalid_1's l1: 0.429898\n",
      "[600]\ttraining's l1: 0.22365\tvalid_1's l1: 0.420405\n",
      "[700]\ttraining's l1: 0.20523\tvalid_1's l1: 0.413958\n",
      "[800]\ttraining's l1: 0.189165\tvalid_1's l1: 0.408729\n",
      "[900]\ttraining's l1: 0.174973\tvalid_1's l1: 0.404153\n",
      "[1000]\ttraining's l1: 0.162605\tvalid_1's l1: 0.400103\n",
      "[1100]\ttraining's l1: 0.150907\tvalid_1's l1: 0.397077\n",
      "[1200]\ttraining's l1: 0.140981\tvalid_1's l1: 0.394478\n",
      "[1300]\ttraining's l1: 0.132393\tvalid_1's l1: 0.391983\n",
      "[1400]\ttraining's l1: 0.124502\tvalid_1's l1: 0.390582\n",
      "[1500]\ttraining's l1: 0.117231\tvalid_1's l1: 0.388712\n",
      "[1600]\ttraining's l1: 0.110336\tvalid_1's l1: 0.387463\n",
      "[1700]\ttraining's l1: 0.10414\tvalid_1's l1: 0.385929\n",
      "[1800]\ttraining's l1: 0.0985554\tvalid_1's l1: 0.385089\n",
      "[1900]\ttraining's l1: 0.0935283\tvalid_1's l1: 0.384024\n",
      "[2000]\ttraining's l1: 0.0886988\tvalid_1's l1: 0.383354\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's l1: 0.0886988\tvalid_1's l1: 0.383354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.9587955942680777"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMRegressor(**LGB_PARAMS, n_estimators=2000, n_jobs = -1)\n",
    "model.fit(X_train, y_train, \n",
    "        eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric='mae',\n",
    "        verbose=100, early_stopping_rounds=100)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "np.log(mean_absolute_error(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(20,15)})\n",
    "cols = list(df.columns)\n",
    "cols.remove('scalar_coupling_constant')\n",
    "cols\n",
    "df_importance = pd.DataFrame({'feature': cols, 'importance': model.feature_importances_})\n",
    "sns_plot = sns.barplot(x=\"importance\", y=\"feature\", palette=\"deep\", data=df_importance.sort_values('importance', ascending=True));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns_plot.get_figure().savefig(\"output.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_x_y_data(some_csv, coupling_type, n_atoms):\n",
    "    full = build_couple_dataframe(some_csv, structures_csv, coupling_type, n_atoms=n_atoms)\n",
    "    \n",
    "    df = take_n_atoms(full, n_atoms)\n",
    "    df = df.fillna(0)\n",
    "    if 'scalar_coupling_constant' in df:\n",
    "        X_data = df.drop(['scalar_coupling_constant'], axis=1).values.astype('float32')\n",
    "        y_data = df['scalar_coupling_constant'].values.astype('float32')\n",
    "    else:\n",
    "        X_data = df.values.astype('float32')\n",
    "        y_data = None\n",
    "    \n",
    "    return X_data, y_data\n",
    "\n",
    "def train_and_predict_for_one_coupling_type(coupling_type, submission, n_atoms, n_folds=6, n_splits=5, random_state=128):\n",
    "    print(f'##########{coupling_type}##########')\n",
    "    \n",
    "    X_data, y_data = build_x_y_data(train_csv, coupling_type, n_atoms)\n",
    "    X_test, _ = build_x_y_data(test_csv, coupling_type, n_atoms)\n",
    "    y_pred = np.zeros(X_test.shape[0], dtype='float32')\n",
    "\n",
    "    cv_score = 0\n",
    "    \n",
    "    if n_folds > n_splits:\n",
    "        n_splits = n_folds\n",
    "    \n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kfold.split(X_data, y_data)):\n",
    "        if fold >= n_folds:\n",
    "            break\n",
    "\n",
    "        X_train, X_val = X_data[train_index], X_data[val_index]\n",
    "        y_train, y_val = y_data[train_index], y_data[val_index]\n",
    "\n",
    "        model = LGBMRegressor(**LGB_PARAMS, n_estimators=1700, n_jobs = -1)\n",
    "        model.fit(X_train, y_train, \n",
    "            eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric='mae',\n",
    "            verbose=100, early_stopping_rounds=250)\n",
    "\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        val_score = np.log(mean_absolute_error(y_val, y_val_pred))\n",
    "        print(f'{coupling_type} Fold {fold} ####### logMAE: {val_score}')\n",
    "        \n",
    "        cv_score += val_score / n_folds\n",
    "        y_pred += model.predict(X_test) / n_folds\n",
    "        \n",
    "        \n",
    "    submission.loc[test_csv['type'] == coupling_type, 'scalar_coupling_constant'] = y_pred\n",
    "    return cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########1JHN##########\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's l1: 0.425607\tvalid_1's l1: 0.526166\n",
      "[200]\ttraining's l1: 0.348286\tvalid_1's l1: 0.473652\n",
      "[300]\ttraining's l1: 0.302545\tvalid_1's l1: 0.447893\n",
      "[400]\ttraining's l1: 0.268049\tvalid_1's l1: 0.431392\n",
      "[500]\ttraining's l1: 0.241275\tvalid_1's l1: 0.420403\n",
      "[600]\ttraining's l1: 0.218919\tvalid_1's l1: 0.411879\n",
      "[700]\ttraining's l1: 0.200568\tvalid_1's l1: 0.405299\n",
      "[800]\ttraining's l1: 0.185751\tvalid_1's l1: 0.400251\n",
      "[900]\ttraining's l1: 0.172624\tvalid_1's l1: 0.396724\n",
      "[1000]\ttraining's l1: 0.159648\tvalid_1's l1: 0.392923\n",
      "[1100]\ttraining's l1: 0.148923\tvalid_1's l1: 0.390083\n",
      "[1200]\ttraining's l1: 0.139453\tvalid_1's l1: 0.387714\n",
      "[1300]\ttraining's l1: 0.131178\tvalid_1's l1: 0.386165\n",
      "[1400]\ttraining's l1: 0.123443\tvalid_1's l1: 0.384526\n",
      "[1500]\ttraining's l1: 0.11601\tvalid_1's l1: 0.383271\n",
      "[1600]\ttraining's l1: 0.109047\tvalid_1's l1: 0.381237\n",
      "[1700]\ttraining's l1: 0.102939\tvalid_1's l1: 0.380445\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1700]\ttraining's l1: 0.102939\tvalid_1's l1: 0.380445\n",
      "1JHN Fold 0 ####### logMAE: -0.9664123468446879\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's l1: 0.421375\tvalid_1's l1: 0.509555\n",
      "[200]\ttraining's l1: 0.343072\tvalid_1's l1: 0.462772\n",
      "[300]\ttraining's l1: 0.297515\tvalid_1's l1: 0.441185\n",
      "[400]\ttraining's l1: 0.268123\tvalid_1's l1: 0.429273\n",
      "[500]\ttraining's l1: 0.241541\tvalid_1's l1: 0.41912\n",
      "[600]\ttraining's l1: 0.22186\tvalid_1's l1: 0.411359\n",
      "[700]\ttraining's l1: 0.204336\tvalid_1's l1: 0.405707\n",
      "[800]\ttraining's l1: 0.189033\tvalid_1's l1: 0.400658\n",
      "[900]\ttraining's l1: 0.175667\tvalid_1's l1: 0.39701\n",
      "[1000]\ttraining's l1: 0.164026\tvalid_1's l1: 0.39385\n",
      "[1100]\ttraining's l1: 0.152979\tvalid_1's l1: 0.391221\n",
      "[1200]\ttraining's l1: 0.142587\tvalid_1's l1: 0.389431\n",
      "[1300]\ttraining's l1: 0.133507\tvalid_1's l1: 0.38733\n",
      "[1400]\ttraining's l1: 0.124772\tvalid_1's l1: 0.385111\n",
      "[1500]\ttraining's l1: 0.117191\tvalid_1's l1: 0.383206\n",
      "[1600]\ttraining's l1: 0.110551\tvalid_1's l1: 0.381809\n",
      "[1700]\ttraining's l1: 0.104134\tvalid_1's l1: 0.380498\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1700]\ttraining's l1: 0.104134\tvalid_1's l1: 0.380498\n",
      "1JHN Fold 1 ####### logMAE: -0.9662736987235032\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's l1: 0.428361\tvalid_1's l1: 0.517853\n",
      "[200]\ttraining's l1: 0.352453\tvalid_1's l1: 0.471734\n",
      "[300]\ttraining's l1: 0.304938\tvalid_1's l1: 0.446675\n",
      "[400]\ttraining's l1: 0.27254\tvalid_1's l1: 0.431794\n",
      "[500]\ttraining's l1: 0.246253\tvalid_1's l1: 0.420982\n",
      "[600]\ttraining's l1: 0.224954\tvalid_1's l1: 0.414163\n",
      "[700]\ttraining's l1: 0.206187\tvalid_1's l1: 0.408564\n",
      "[800]\ttraining's l1: 0.189684\tvalid_1's l1: 0.403258\n",
      "[900]\ttraining's l1: 0.176455\tvalid_1's l1: 0.399189\n",
      "[1000]\ttraining's l1: 0.163816\tvalid_1's l1: 0.395423\n",
      "[1100]\ttraining's l1: 0.152662\tvalid_1's l1: 0.39243\n",
      "[1200]\ttraining's l1: 0.142603\tvalid_1's l1: 0.389693\n",
      "[1300]\ttraining's l1: 0.133713\tvalid_1's l1: 0.38751\n",
      "[1400]\ttraining's l1: 0.125209\tvalid_1's l1: 0.385599\n",
      "[1500]\ttraining's l1: 0.118173\tvalid_1's l1: 0.384178\n",
      "[1600]\ttraining's l1: 0.111345\tvalid_1's l1: 0.38266\n",
      "[1700]\ttraining's l1: 0.105374\tvalid_1's l1: 0.381664\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1700]\ttraining's l1: 0.105374\tvalid_1's l1: 0.381664\n",
      "1JHN Fold 2 ####### logMAE: -0.9632158737547006\n",
      "##########1JHC##########\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's l1: 1.16227\tvalid_1's l1: 1.21206\n",
      "[200]\ttraining's l1: 0.990709\tvalid_1's l1: 1.07062\n",
      "[300]\ttraining's l1: 0.8941\tvalid_1's l1: 0.999602\n",
      "[400]\ttraining's l1: 0.823492\tvalid_1's l1: 0.950112\n",
      "[500]\ttraining's l1: 0.770175\tvalid_1's l1: 0.91457\n",
      "[600]\ttraining's l1: 0.726486\tvalid_1's l1: 0.888199\n",
      "[700]\ttraining's l1: 0.689921\tvalid_1's l1: 0.867569\n",
      "[800]\ttraining's l1: 0.65811\tvalid_1's l1: 0.850164\n",
      "[900]\ttraining's l1: 0.630432\tvalid_1's l1: 0.835902\n",
      "[1000]\ttraining's l1: 0.605185\tvalid_1's l1: 0.823089\n",
      "[1100]\ttraining's l1: 0.582746\tvalid_1's l1: 0.812031\n",
      "[1200]\ttraining's l1: 0.563146\tvalid_1's l1: 0.803404\n",
      "[1300]\ttraining's l1: 0.544557\tvalid_1's l1: 0.795222\n",
      "[1400]\ttraining's l1: 0.527461\tvalid_1's l1: 0.788039\n",
      "[1500]\ttraining's l1: 0.511416\tvalid_1's l1: 0.781087\n",
      "[1600]\ttraining's l1: 0.496303\tvalid_1's l1: 0.774676\n",
      "[1700]\ttraining's l1: 0.482023\tvalid_1's l1: 0.768761\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1700]\ttraining's l1: 0.482023\tvalid_1's l1: 0.768761\n",
      "1JHC Fold 0 ####### logMAE: -0.26297469480463753\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's l1: 1.1595\tvalid_1's l1: 1.20698\n",
      "[200]\ttraining's l1: 0.991692\tvalid_1's l1: 1.06809\n",
      "[300]\ttraining's l1: 0.893113\tvalid_1's l1: 0.994103\n",
      "[400]\ttraining's l1: 0.824292\tvalid_1's l1: 0.946892\n",
      "[500]\ttraining's l1: 0.771729\tvalid_1's l1: 0.912626\n",
      "[600]\ttraining's l1: 0.728325\tvalid_1's l1: 0.885812\n",
      "[700]\ttraining's l1: 0.690993\tvalid_1's l1: 0.864213\n",
      "[800]\ttraining's l1: 0.659719\tvalid_1's l1: 0.84743\n",
      "[900]\ttraining's l1: 0.632298\tvalid_1's l1: 0.833504\n",
      "[1000]\ttraining's l1: 0.607591\tvalid_1's l1: 0.82091\n",
      "[1100]\ttraining's l1: 0.58541\tvalid_1's l1: 0.810054\n",
      "[1200]\ttraining's l1: 0.565073\tvalid_1's l1: 0.800507\n",
      "[1300]\ttraining's l1: 0.546392\tvalid_1's l1: 0.791927\n",
      "[1400]\ttraining's l1: 0.529236\tvalid_1's l1: 0.784274\n",
      "[1500]\ttraining's l1: 0.513521\tvalid_1's l1: 0.777525\n",
      "[1600]\ttraining's l1: 0.498674\tvalid_1's l1: 0.771504\n",
      "[1700]\ttraining's l1: 0.484263\tvalid_1's l1: 0.765567\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1700]\ttraining's l1: 0.484263\tvalid_1's l1: 0.765567\n",
      "1JHC Fold 1 ####### logMAE: -0.26713909088158755\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's l1: 1.17114\tvalid_1's l1: 1.2245\n",
      "[200]\ttraining's l1: 0.991742\tvalid_1's l1: 1.07432\n",
      "[300]\ttraining's l1: 0.893468\tvalid_1's l1: 1.00107\n",
      "[400]\ttraining's l1: 0.82525\tvalid_1's l1: 0.953843\n",
      "[500]\ttraining's l1: 0.771792\tvalid_1's l1: 0.918396\n",
      "[600]\ttraining's l1: 0.726734\tvalid_1's l1: 0.890427\n",
      "[700]\ttraining's l1: 0.690442\tvalid_1's l1: 0.868578\n",
      "[800]\ttraining's l1: 0.658971\tvalid_1's l1: 0.851479\n",
      "[900]\ttraining's l1: 0.631543\tvalid_1's l1: 0.837629\n",
      "[1000]\ttraining's l1: 0.606479\tvalid_1's l1: 0.825144\n",
      "[1100]\ttraining's l1: 0.584471\tvalid_1's l1: 0.813945\n",
      "[1200]\ttraining's l1: 0.564412\tvalid_1's l1: 0.804704\n",
      "[1300]\ttraining's l1: 0.54528\tvalid_1's l1: 0.796024\n",
      "[1400]\ttraining's l1: 0.527828\tvalid_1's l1: 0.788048\n",
      "[1500]\ttraining's l1: 0.511506\tvalid_1's l1: 0.781343\n",
      "[1600]\ttraining's l1: 0.49674\tvalid_1's l1: 0.775441\n",
      "[1700]\ttraining's l1: 0.482811\tvalid_1's l1: 0.769922\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1700]\ttraining's l1: 0.482811\tvalid_1's l1: 0.769922\n",
      "1JHC Fold 2 ####### logMAE: -0.2614659413515445\n",
      "##########2JHH##########\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's l1: 0.255552\tvalid_1's l1: 0.279381\n",
      "[200]\ttraining's l1: 0.208245\tvalid_1's l1: 0.2431\n",
      "[300]\ttraining's l1: 0.18354\tvalid_1's l1: 0.226392\n",
      "[400]\ttraining's l1: 0.166753\tvalid_1's l1: 0.216068\n",
      "[500]\ttraining's l1: 0.153232\tvalid_1's l1: 0.208105\n",
      "[600]\ttraining's l1: 0.142594\tvalid_1's l1: 0.202312\n",
      "[700]\ttraining's l1: 0.133856\tvalid_1's l1: 0.197944\n",
      "[800]\ttraining's l1: 0.126155\tvalid_1's l1: 0.194343\n",
      "[900]\ttraining's l1: 0.119424\tvalid_1's l1: 0.191366\n",
      "[1000]\ttraining's l1: 0.113303\tvalid_1's l1: 0.188594\n",
      "[1100]\ttraining's l1: 0.107904\tvalid_1's l1: 0.186521\n",
      "[1200]\ttraining's l1: 0.10311\tvalid_1's l1: 0.184567\n",
      "[1300]\ttraining's l1: 0.0987357\tvalid_1's l1: 0.182931\n",
      "[1400]\ttraining's l1: 0.0946086\tvalid_1's l1: 0.181416\n",
      "[1500]\ttraining's l1: 0.090751\tvalid_1's l1: 0.180109\n",
      "[1600]\ttraining's l1: 0.0872807\tvalid_1's l1: 0.178913\n",
      "[1700]\ttraining's l1: 0.0841233\tvalid_1's l1: 0.17786\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1700]\ttraining's l1: 0.0841233\tvalid_1's l1: 0.17786\n",
      "2JHH Fold 0 ####### logMAE: -1.7267610013132393\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's l1: 0.256411\tvalid_1's l1: 0.27694\n",
      "[200]\ttraining's l1: 0.208739\tvalid_1's l1: 0.240137\n",
      "[300]\ttraining's l1: 0.183692\tvalid_1's l1: 0.222987\n",
      "[400]\ttraining's l1: 0.16664\tvalid_1's l1: 0.212545\n",
      "[500]\ttraining's l1: 0.153181\tvalid_1's l1: 0.20496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600]\ttraining's l1: 0.142994\tvalid_1's l1: 0.199685\n",
      "[700]\ttraining's l1: 0.134197\tvalid_1's l1: 0.195337\n",
      "[800]\ttraining's l1: 0.126552\tvalid_1's l1: 0.191702\n",
      "[900]\ttraining's l1: 0.119549\tvalid_1's l1: 0.188594\n",
      "[1000]\ttraining's l1: 0.113622\tvalid_1's l1: 0.186139\n",
      "[1100]\ttraining's l1: 0.108122\tvalid_1's l1: 0.183991\n",
      "[1200]\ttraining's l1: 0.10314\tvalid_1's l1: 0.181967\n",
      "[1300]\ttraining's l1: 0.0987303\tvalid_1's l1: 0.180104\n",
      "[1400]\ttraining's l1: 0.0944959\tvalid_1's l1: 0.178605\n",
      "[1500]\ttraining's l1: 0.0906879\tvalid_1's l1: 0.177169\n",
      "[1600]\ttraining's l1: 0.0871391\tvalid_1's l1: 0.175931\n",
      "[1700]\ttraining's l1: 0.0838757\tvalid_1's l1: 0.174787\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1700]\ttraining's l1: 0.0838757\tvalid_1's l1: 0.174787\n",
      "2JHH Fold 1 ####### logMAE: -1.744186078256796\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's l1: 0.257976\tvalid_1's l1: 0.278588\n",
      "[200]\ttraining's l1: 0.209531\tvalid_1's l1: 0.24137\n",
      "[300]\ttraining's l1: 0.184562\tvalid_1's l1: 0.224311\n",
      "[400]\ttraining's l1: 0.167337\tvalid_1's l1: 0.213959\n",
      "[500]\ttraining's l1: 0.154199\tvalid_1's l1: 0.206678\n",
      "[600]\ttraining's l1: 0.143788\tvalid_1's l1: 0.201294\n",
      "[700]\ttraining's l1: 0.134754\tvalid_1's l1: 0.196883\n",
      "[800]\ttraining's l1: 0.127041\tvalid_1's l1: 0.193162\n",
      "[900]\ttraining's l1: 0.120216\tvalid_1's l1: 0.190016\n",
      "[1000]\ttraining's l1: 0.114143\tvalid_1's l1: 0.187469\n",
      "[1100]\ttraining's l1: 0.108792\tvalid_1's l1: 0.185283\n",
      "[1200]\ttraining's l1: 0.103704\tvalid_1's l1: 0.183321\n",
      "[1300]\ttraining's l1: 0.0991915\tvalid_1's l1: 0.181505\n",
      "[1400]\ttraining's l1: 0.0951407\tvalid_1's l1: 0.180011\n",
      "[1500]\ttraining's l1: 0.0912867\tvalid_1's l1: 0.178622\n",
      "[1600]\ttraining's l1: 0.0878559\tvalid_1's l1: 0.177339\n",
      "[1700]\ttraining's l1: 0.0846133\tvalid_1's l1: 0.176269\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1700]\ttraining's l1: 0.0846133\tvalid_1's l1: 0.176269\n",
      "2JHH Fold 2 ####### logMAE: -1.7357429150453851\n",
      "##########2JHN##########\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's l1: 0.181741\tvalid_1's l1: 0.214628\n",
      "[200]\ttraining's l1: 0.145314\tvalid_1's l1: 0.189809\n",
      "[300]\ttraining's l1: 0.12518\tvalid_1's l1: 0.177714\n",
      "[400]\ttraining's l1: 0.111988\tvalid_1's l1: 0.170351\n",
      "[500]\ttraining's l1: 0.101472\tvalid_1's l1: 0.16499\n",
      "[600]\ttraining's l1: 0.0930103\tvalid_1's l1: 0.16102\n",
      "[700]\ttraining's l1: 0.0861436\tvalid_1's l1: 0.158034\n",
      "[800]\ttraining's l1: 0.0800565\tvalid_1's l1: 0.155252\n",
      "[900]\ttraining's l1: 0.0745473\tvalid_1's l1: 0.152902\n",
      "[1000]\ttraining's l1: 0.0698064\tvalid_1's l1: 0.151173\n",
      "[1100]\ttraining's l1: 0.0653775\tvalid_1's l1: 0.1496\n",
      "[1200]\ttraining's l1: 0.061379\tvalid_1's l1: 0.14823\n",
      "[1300]\ttraining's l1: 0.0577401\tvalid_1's l1: 0.147054\n",
      "[1400]\ttraining's l1: 0.0545977\tvalid_1's l1: 0.146032\n",
      "[1500]\ttraining's l1: 0.051654\tvalid_1's l1: 0.145007\n",
      "[1600]\ttraining's l1: 0.048825\tvalid_1's l1: 0.144125\n",
      "[1700]\ttraining's l1: 0.0462346\tvalid_1's l1: 0.143441\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1700]\ttraining's l1: 0.0462346\tvalid_1's l1: 0.143441\n",
      "2JHN Fold 0 ####### logMAE: -1.9418348766710885\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's l1: 0.183245\tvalid_1's l1: 0.214936\n",
      "[200]\ttraining's l1: 0.147451\tvalid_1's l1: 0.190214\n",
      "[300]\ttraining's l1: 0.126774\tvalid_1's l1: 0.177947\n",
      "[400]\ttraining's l1: 0.112989\tvalid_1's l1: 0.170595\n",
      "[500]\ttraining's l1: 0.102184\tvalid_1's l1: 0.164933\n",
      "[600]\ttraining's l1: 0.0935238\tvalid_1's l1: 0.16105\n",
      "[700]\ttraining's l1: 0.0862119\tvalid_1's l1: 0.157866\n",
      "[800]\ttraining's l1: 0.0800753\tvalid_1's l1: 0.155318\n",
      "[900]\ttraining's l1: 0.0744282\tvalid_1's l1: 0.153171\n",
      "[1000]\ttraining's l1: 0.0697478\tvalid_1's l1: 0.151423\n",
      "[1100]\ttraining's l1: 0.0654848\tvalid_1's l1: 0.149869\n",
      "[1200]\ttraining's l1: 0.0614403\tvalid_1's l1: 0.148321\n",
      "[1300]\ttraining's l1: 0.0579732\tvalid_1's l1: 0.1472\n",
      "[1400]\ttraining's l1: 0.054647\tvalid_1's l1: 0.146024\n",
      "[1500]\ttraining's l1: 0.0517051\tvalid_1's l1: 0.145261\n",
      "[1600]\ttraining's l1: 0.0490623\tvalid_1's l1: 0.144453\n",
      "[1700]\ttraining's l1: 0.0466604\tvalid_1's l1: 0.143724\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1700]\ttraining's l1: 0.0466604\tvalid_1's l1: 0.143724\n",
      "2JHN Fold 1 ####### logMAE: -1.9398580949463047\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's l1: 0.189153\tvalid_1's l1: 0.218149\n",
      "[200]\ttraining's l1: 0.15079\tvalid_1's l1: 0.191506\n",
      "[300]\ttraining's l1: 0.129715\tvalid_1's l1: 0.178385\n",
      "[400]\ttraining's l1: 0.115573\tvalid_1's l1: 0.170772\n",
      "[500]\ttraining's l1: 0.104519\tvalid_1's l1: 0.165178\n",
      "[600]\ttraining's l1: 0.0953292\tvalid_1's l1: 0.160969\n",
      "[700]\ttraining's l1: 0.0880159\tvalid_1's l1: 0.157975\n",
      "[800]\ttraining's l1: 0.0815514\tvalid_1's l1: 0.155232\n",
      "[900]\ttraining's l1: 0.0759334\tvalid_1's l1: 0.15305\n",
      "[1000]\ttraining's l1: 0.0711606\tvalid_1's l1: 0.151296\n",
      "[1100]\ttraining's l1: 0.0668139\tvalid_1's l1: 0.149796\n",
      "[1200]\ttraining's l1: 0.06262\tvalid_1's l1: 0.148472\n",
      "[1300]\ttraining's l1: 0.0589088\tvalid_1's l1: 0.147285\n",
      "[1400]\ttraining's l1: 0.0556533\tvalid_1's l1: 0.146359\n",
      "[1500]\ttraining's l1: 0.0526872\tvalid_1's l1: 0.145469\n",
      "[1600]\ttraining's l1: 0.0500234\tvalid_1's l1: 0.1447\n",
      "[1700]\ttraining's l1: 0.0475296\tvalid_1's l1: 0.143937\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1700]\ttraining's l1: 0.0475296\tvalid_1's l1: 0.143937\n",
      "2JHN Fold 2 ####### logMAE: -1.9383821295453005\n",
      "##########2JHC##########\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's l1: 0.495706\tvalid_1's l1: 0.510023\n",
      "[200]\ttraining's l1: 0.420271\tvalid_1's l1: 0.442749\n",
      "[300]\ttraining's l1: 0.379852\tvalid_1's l1: 0.409373\n",
      "[400]\ttraining's l1: 0.352237\tvalid_1's l1: 0.387333\n",
      "[500]\ttraining's l1: 0.331172\tvalid_1's l1: 0.371559\n",
      "[600]\ttraining's l1: 0.314172\tvalid_1's l1: 0.359061\n",
      "[700]\ttraining's l1: 0.299984\tvalid_1's l1: 0.349069\n",
      "[800]\ttraining's l1: 0.287684\tvalid_1's l1: 0.340618\n",
      "[900]\ttraining's l1: 0.277259\tvalid_1's l1: 0.333928\n",
      "[1000]\ttraining's l1: 0.267605\tvalid_1's l1: 0.327637\n",
      "[1100]\ttraining's l1: 0.25891\tvalid_1's l1: 0.322243\n",
      "[1200]\ttraining's l1: 0.251275\tvalid_1's l1: 0.317805\n",
      "[1300]\ttraining's l1: 0.244298\tvalid_1's l1: 0.313687\n",
      "[1400]\ttraining's l1: 0.237676\tvalid_1's l1: 0.309944\n",
      "[1500]\ttraining's l1: 0.231727\tvalid_1's l1: 0.306719\n",
      "[1600]\ttraining's l1: 0.226145\tvalid_1's l1: 0.30369\n",
      "[1700]\ttraining's l1: 0.220932\tvalid_1's l1: 0.300926\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1700]\ttraining's l1: 0.220932\tvalid_1's l1: 0.300926\n",
      "2JHC Fold 0 ####### logMAE: -1.2008906996174815\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's l1: 0.498263\tvalid_1's l1: 0.513606\n",
      "[200]\ttraining's l1: 0.422064\tvalid_1's l1: 0.445148\n",
      "[300]\ttraining's l1: 0.38205\tvalid_1's l1: 0.411229\n",
      "[400]\ttraining's l1: 0.354363\tvalid_1's l1: 0.389464\n",
      "[500]\ttraining's l1: 0.332743\tvalid_1's l1: 0.372616\n",
      "[600]\ttraining's l1: 0.315668\tvalid_1's l1: 0.360266\n",
      "[700]\ttraining's l1: 0.301306\tvalid_1's l1: 0.350123\n",
      "[800]\ttraining's l1: 0.289144\tvalid_1's l1: 0.341612\n",
      "[900]\ttraining's l1: 0.278138\tvalid_1's l1: 0.334292\n",
      "[1000]\ttraining's l1: 0.268673\tvalid_1's l1: 0.328265\n",
      "[1100]\ttraining's l1: 0.260019\tvalid_1's l1: 0.322693\n",
      "[1200]\ttraining's l1: 0.252238\tvalid_1's l1: 0.318007\n",
      "[1300]\ttraining's l1: 0.245074\tvalid_1's l1: 0.313679\n",
      "[1400]\ttraining's l1: 0.238646\tvalid_1's l1: 0.310055\n",
      "[1500]\ttraining's l1: 0.232671\tvalid_1's l1: 0.306701\n",
      "[1600]\ttraining's l1: 0.226933\tvalid_1's l1: 0.303499\n",
      "[1700]\ttraining's l1: 0.221655\tvalid_1's l1: 0.300609\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1700]\ttraining's l1: 0.221655\tvalid_1's l1: 0.300609\n",
      "2JHC Fold 1 ####### logMAE: -1.2019452706588223\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's l1: 0.500162\tvalid_1's l1: 0.514074\n",
      "[200]\ttraining's l1: 0.422345\tvalid_1's l1: 0.444506\n",
      "[300]\ttraining's l1: 0.381031\tvalid_1's l1: 0.409736\n",
      "[400]\ttraining's l1: 0.352775\tvalid_1's l1: 0.387125\n",
      "[500]\ttraining's l1: 0.331397\tvalid_1's l1: 0.370746\n",
      "[600]\ttraining's l1: 0.314508\tvalid_1's l1: 0.358552\n",
      "[700]\ttraining's l1: 0.300119\tvalid_1's l1: 0.348465\n",
      "[800]\ttraining's l1: 0.287936\tvalid_1's l1: 0.340044\n",
      "[900]\ttraining's l1: 0.277655\tvalid_1's l1: 0.333505\n",
      "[1000]\ttraining's l1: 0.268111\tvalid_1's l1: 0.327415\n",
      "[1100]\ttraining's l1: 0.259637\tvalid_1's l1: 0.322195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1200]\ttraining's l1: 0.251944\tvalid_1's l1: 0.317589\n",
      "[1300]\ttraining's l1: 0.244847\tvalid_1's l1: 0.313432\n",
      "[1400]\ttraining's l1: 0.238256\tvalid_1's l1: 0.309571\n",
      "[1500]\ttraining's l1: 0.23224\tvalid_1's l1: 0.306206\n",
      "[1600]\ttraining's l1: 0.226625\tvalid_1's l1: 0.303174\n",
      "[1700]\ttraining's l1: 0.221414\tvalid_1's l1: 0.30031\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1700]\ttraining's l1: 0.221414\tvalid_1's l1: 0.30031\n",
      "2JHC Fold 2 ####### logMAE: -1.2029405580628416\n",
      "##########3JHH##########\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's l1: 0.283533\tvalid_1's l1: 0.295678\n",
      "[200]\ttraining's l1: 0.23191\tvalid_1's l1: 0.251852\n",
      "[300]\ttraining's l1: 0.205673\tvalid_1's l1: 0.231629\n",
      "[400]\ttraining's l1: 0.188386\tvalid_1's l1: 0.219033\n",
      "[500]\ttraining's l1: 0.175295\tvalid_1's l1: 0.209934\n",
      "[600]\ttraining's l1: 0.164376\tvalid_1's l1: 0.20281\n",
      "[700]\ttraining's l1: 0.155533\tvalid_1's l1: 0.197409\n",
      "[800]\ttraining's l1: 0.147782\tvalid_1's l1: 0.192961\n",
      "[900]\ttraining's l1: 0.140934\tvalid_1's l1: 0.189159\n",
      "[1000]\ttraining's l1: 0.134982\tvalid_1's l1: 0.186069\n",
      "[1100]\ttraining's l1: 0.129549\tvalid_1's l1: 0.183127\n",
      "[1200]\ttraining's l1: 0.124724\tvalid_1's l1: 0.180718\n",
      "[1300]\ttraining's l1: 0.120261\tvalid_1's l1: 0.178639\n",
      "[1400]\ttraining's l1: 0.11614\tvalid_1's l1: 0.17665\n",
      "[1500]\ttraining's l1: 0.112273\tvalid_1's l1: 0.17486\n",
      "[1600]\ttraining's l1: 0.108816\tvalid_1's l1: 0.173345\n",
      "[1700]\ttraining's l1: 0.105479\tvalid_1's l1: 0.171895\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1700]\ttraining's l1: 0.105479\tvalid_1's l1: 0.171895\n",
      "3JHH Fold 0 ####### logMAE: -1.7608728747254512\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's l1: 0.282927\tvalid_1's l1: 0.296848\n",
      "[200]\ttraining's l1: 0.233388\tvalid_1's l1: 0.254301\n",
      "[300]\ttraining's l1: 0.206876\tvalid_1's l1: 0.233726\n",
      "[400]\ttraining's l1: 0.189073\tvalid_1's l1: 0.220817\n",
      "[500]\ttraining's l1: 0.175903\tvalid_1's l1: 0.211946\n",
      "[600]\ttraining's l1: 0.164917\tvalid_1's l1: 0.205005\n",
      "[700]\ttraining's l1: 0.156241\tvalid_1's l1: 0.199769\n",
      "[800]\ttraining's l1: 0.148492\tvalid_1's l1: 0.195215\n",
      "[900]\ttraining's l1: 0.141852\tvalid_1's l1: 0.191525\n",
      "[1000]\ttraining's l1: 0.135921\tvalid_1's l1: 0.188361\n",
      "[1100]\ttraining's l1: 0.130455\tvalid_1's l1: 0.185508\n",
      "[1200]\ttraining's l1: 0.12572\tvalid_1's l1: 0.183257\n",
      "[1300]\ttraining's l1: 0.121261\tvalid_1's l1: 0.181092\n",
      "[1400]\ttraining's l1: 0.117172\tvalid_1's l1: 0.179141\n",
      "[1500]\ttraining's l1: 0.113217\tvalid_1's l1: 0.177393\n",
      "[1600]\ttraining's l1: 0.109678\tvalid_1's l1: 0.175902\n",
      "[1700]\ttraining's l1: 0.106385\tvalid_1's l1: 0.174495\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1700]\ttraining's l1: 0.106385\tvalid_1's l1: 0.174495\n",
      "3JHH Fold 1 ####### logMAE: -1.7458606079442873\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's l1: 0.280594\tvalid_1's l1: 0.294458\n",
      "[200]\ttraining's l1: 0.230776\tvalid_1's l1: 0.251878\n",
      "[300]\ttraining's l1: 0.204979\tvalid_1's l1: 0.23185\n",
      "[400]\ttraining's l1: 0.187202\tvalid_1's l1: 0.218778\n",
      "[500]\ttraining's l1: 0.174123\tvalid_1's l1: 0.210024\n",
      "[600]\ttraining's l1: 0.163468\tvalid_1's l1: 0.203281\n",
      "[700]\ttraining's l1: 0.154394\tvalid_1's l1: 0.197814\n",
      "[800]\ttraining's l1: 0.146862\tvalid_1's l1: 0.19334\n",
      "[900]\ttraining's l1: 0.140236\tvalid_1's l1: 0.189617\n",
      "[1000]\ttraining's l1: 0.134422\tvalid_1's l1: 0.186564\n",
      "[1100]\ttraining's l1: 0.129187\tvalid_1's l1: 0.183789\n",
      "[1200]\ttraining's l1: 0.124433\tvalid_1's l1: 0.18141\n",
      "[1300]\ttraining's l1: 0.120027\tvalid_1's l1: 0.179318\n",
      "[1400]\ttraining's l1: 0.115853\tvalid_1's l1: 0.177376\n",
      "[1500]\ttraining's l1: 0.112052\tvalid_1's l1: 0.175596\n",
      "[1600]\ttraining's l1: 0.108534\tvalid_1's l1: 0.174056\n",
      "[1700]\ttraining's l1: 0.105174\tvalid_1's l1: 0.17265\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1700]\ttraining's l1: 0.105174\tvalid_1's l1: 0.17265\n",
      "3JHH Fold 2 ####### logMAE: -1.7564889390321983\n",
      "##########3JHC##########\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's l1: 0.554319\tvalid_1's l1: 0.565001\n",
      "[200]\ttraining's l1: 0.471883\tvalid_1's l1: 0.490208\n",
      "[300]\ttraining's l1: 0.428403\tvalid_1's l1: 0.452453\n",
      "[400]\ttraining's l1: 0.399678\tvalid_1's l1: 0.428457\n",
      "[500]\ttraining's l1: 0.377563\tvalid_1's l1: 0.410907\n",
      "[600]\ttraining's l1: 0.360059\tvalid_1's l1: 0.397587\n",
      "[700]\ttraining's l1: 0.345069\tvalid_1's l1: 0.386605\n",
      "[800]\ttraining's l1: 0.332358\tvalid_1's l1: 0.377573\n",
      "[900]\ttraining's l1: 0.321404\tvalid_1's l1: 0.370307\n",
      "[1000]\ttraining's l1: 0.31162\tvalid_1's l1: 0.36385\n",
      "[1100]\ttraining's l1: 0.302514\tvalid_1's l1: 0.357952\n",
      "[1200]\ttraining's l1: 0.294313\tvalid_1's l1: 0.352747\n",
      "[1300]\ttraining's l1: 0.287012\tvalid_1's l1: 0.348208\n",
      "[1400]\ttraining's l1: 0.28022\tvalid_1's l1: 0.344065\n",
      "[1500]\ttraining's l1: 0.273828\tvalid_1's l1: 0.340336\n",
      "[1600]\ttraining's l1: 0.267784\tvalid_1's l1: 0.336836\n",
      "[1700]\ttraining's l1: 0.26202\tvalid_1's l1: 0.333595\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1700]\ttraining's l1: 0.26202\tvalid_1's l1: 0.333595\n",
      "3JHC Fold 0 ####### logMAE: -1.0978277247874002\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's l1: 0.550777\tvalid_1's l1: 0.563574\n",
      "[200]\ttraining's l1: 0.471398\tvalid_1's l1: 0.490774\n",
      "[300]\ttraining's l1: 0.428569\tvalid_1's l1: 0.453342\n",
      "[400]\ttraining's l1: 0.399171\tvalid_1's l1: 0.428999\n",
      "[500]\ttraining's l1: 0.377197\tvalid_1's l1: 0.410962\n",
      "[600]\ttraining's l1: 0.359422\tvalid_1's l1: 0.397228\n",
      "[700]\ttraining's l1: 0.345017\tvalid_1's l1: 0.38656\n",
      "[800]\ttraining's l1: 0.332289\tvalid_1's l1: 0.37728\n",
      "[900]\ttraining's l1: 0.321314\tvalid_1's l1: 0.369502\n",
      "[1000]\ttraining's l1: 0.311514\tvalid_1's l1: 0.362901\n",
      "[1100]\ttraining's l1: 0.302689\tvalid_1's l1: 0.357179\n",
      "[1200]\ttraining's l1: 0.294295\tvalid_1's l1: 0.351696\n",
      "[1300]\ttraining's l1: 0.286906\tvalid_1's l1: 0.347091\n",
      "[1400]\ttraining's l1: 0.280084\tvalid_1's l1: 0.342922\n",
      "[1500]\ttraining's l1: 0.273598\tvalid_1's l1: 0.338965\n",
      "[1600]\ttraining's l1: 0.267685\tvalid_1's l1: 0.335506\n",
      "[1700]\ttraining's l1: 0.262096\tvalid_1's l1: 0.33229\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1700]\ttraining's l1: 0.262096\tvalid_1's l1: 0.33229\n",
      "3JHC Fold 1 ####### logMAE: -1.1017460643040917\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's l1: 0.552579\tvalid_1's l1: 0.561946\n",
      "[200]\ttraining's l1: 0.47132\tvalid_1's l1: 0.487775\n",
      "[300]\ttraining's l1: 0.428481\tvalid_1's l1: 0.450872\n",
      "[400]\ttraining's l1: 0.399811\tvalid_1's l1: 0.427176\n",
      "[500]\ttraining's l1: 0.378165\tvalid_1's l1: 0.410192\n",
      "[600]\ttraining's l1: 0.360481\tvalid_1's l1: 0.39665\n",
      "[700]\ttraining's l1: 0.346151\tvalid_1's l1: 0.386064\n",
      "[800]\ttraining's l1: 0.333126\tvalid_1's l1: 0.376773\n",
      "[900]\ttraining's l1: 0.321964\tvalid_1's l1: 0.368951\n",
      "[1000]\ttraining's l1: 0.312282\tvalid_1's l1: 0.362663\n",
      "[1100]\ttraining's l1: 0.303396\tvalid_1's l1: 0.356736\n",
      "[1200]\ttraining's l1: 0.295374\tvalid_1's l1: 0.351688\n",
      "[1300]\ttraining's l1: 0.287817\tvalid_1's l1: 0.346993\n",
      "[1400]\ttraining's l1: 0.281062\tvalid_1's l1: 0.342983\n",
      "[1500]\ttraining's l1: 0.274567\tvalid_1's l1: 0.339198\n",
      "[1600]\ttraining's l1: 0.268519\tvalid_1's l1: 0.335696\n",
      "[1700]\ttraining's l1: 0.262792\tvalid_1's l1: 0.332432\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1700]\ttraining's l1: 0.262792\tvalid_1's l1: 0.332432\n",
      "3JHC Fold 2 ####### logMAE: -1.10132067659933\n",
      "##########3JHN##########\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's l1: 0.149486\tvalid_1's l1: 0.171941\n",
      "[200]\ttraining's l1: 0.119957\tvalid_1's l1: 0.151478\n",
      "[300]\ttraining's l1: 0.102724\tvalid_1's l1: 0.141227\n",
      "[400]\ttraining's l1: 0.0919529\tvalid_1's l1: 0.135171\n",
      "[500]\ttraining's l1: 0.0830828\tvalid_1's l1: 0.130604\n",
      "[600]\ttraining's l1: 0.0757729\tvalid_1's l1: 0.127147\n",
      "[700]\ttraining's l1: 0.0693534\tvalid_1's l1: 0.124467\n",
      "[800]\ttraining's l1: 0.0640181\tvalid_1's l1: 0.122371\n",
      "[900]\ttraining's l1: 0.0595266\tvalid_1's l1: 0.120602\n",
      "[1000]\ttraining's l1: 0.0555794\tvalid_1's l1: 0.119058\n",
      "[1100]\ttraining's l1: 0.0520614\tvalid_1's l1: 0.117846\n",
      "[1200]\ttraining's l1: 0.0490017\tvalid_1's l1: 0.1168\n",
      "[1300]\ttraining's l1: 0.0462279\tvalid_1's l1: 0.115884\n",
      "[1400]\ttraining's l1: 0.0436293\tvalid_1's l1: 0.115157\n",
      "[1500]\ttraining's l1: 0.0412685\tvalid_1's l1: 0.114412\n",
      "[1600]\ttraining's l1: 0.0391277\tvalid_1's l1: 0.113706\n",
      "[1700]\ttraining's l1: 0.0371828\tvalid_1's l1: 0.113111\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1700]\ttraining's l1: 0.0371828\tvalid_1's l1: 0.113111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3JHN Fold 0 ####### logMAE: -2.1793846720572048\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's l1: 0.150601\tvalid_1's l1: 0.170274\n",
      "[200]\ttraining's l1: 0.120247\tvalid_1's l1: 0.148713\n",
      "[300]\ttraining's l1: 0.103411\tvalid_1's l1: 0.138439\n",
      "[400]\ttraining's l1: 0.0915548\tvalid_1's l1: 0.131988\n",
      "[500]\ttraining's l1: 0.0821794\tvalid_1's l1: 0.127387\n",
      "[600]\ttraining's l1: 0.0747639\tvalid_1's l1: 0.12414\n",
      "[700]\ttraining's l1: 0.0688157\tvalid_1's l1: 0.121637\n",
      "[800]\ttraining's l1: 0.0637677\tvalid_1's l1: 0.119458\n",
      "[900]\ttraining's l1: 0.0593007\tvalid_1's l1: 0.117688\n",
      "[1000]\ttraining's l1: 0.0553622\tvalid_1's l1: 0.116108\n",
      "[1100]\ttraining's l1: 0.0519724\tvalid_1's l1: 0.115016\n",
      "[1200]\ttraining's l1: 0.0489343\tvalid_1's l1: 0.114021\n",
      "[1300]\ttraining's l1: 0.0462173\tvalid_1's l1: 0.113138\n",
      "[1400]\ttraining's l1: 0.0435734\tvalid_1's l1: 0.112309\n",
      "[1500]\ttraining's l1: 0.0412122\tvalid_1's l1: 0.111555\n",
      "[1600]\ttraining's l1: 0.0390703\tvalid_1's l1: 0.110862\n",
      "[1700]\ttraining's l1: 0.0371287\tvalid_1's l1: 0.110291\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1700]\ttraining's l1: 0.0371287\tvalid_1's l1: 0.110291\n",
      "3JHN Fold 1 ####### logMAE: -2.2046334474335603\n",
      "Training until validation scores don't improve for 250 rounds\n",
      "[100]\ttraining's l1: 0.150407\tvalid_1's l1: 0.172998\n",
      "[200]\ttraining's l1: 0.120513\tvalid_1's l1: 0.152059\n",
      "[300]\ttraining's l1: 0.103013\tvalid_1's l1: 0.141317\n",
      "[400]\ttraining's l1: 0.0914979\tvalid_1's l1: 0.135198\n",
      "[500]\ttraining's l1: 0.082522\tvalid_1's l1: 0.130957\n",
      "[600]\ttraining's l1: 0.0753832\tvalid_1's l1: 0.127926\n",
      "[700]\ttraining's l1: 0.0694035\tvalid_1's l1: 0.125316\n",
      "[800]\ttraining's l1: 0.0642126\tvalid_1's l1: 0.123261\n",
      "[900]\ttraining's l1: 0.0597726\tvalid_1's l1: 0.121524\n",
      "[1000]\ttraining's l1: 0.0558123\tvalid_1's l1: 0.120134\n",
      "[1100]\ttraining's l1: 0.052405\tvalid_1's l1: 0.118927\n",
      "[1200]\ttraining's l1: 0.0490991\tvalid_1's l1: 0.117837\n",
      "[1300]\ttraining's l1: 0.0462426\tvalid_1's l1: 0.116915\n",
      "[1400]\ttraining's l1: 0.0436093\tvalid_1's l1: 0.11605\n",
      "[1500]\ttraining's l1: 0.041333\tvalid_1's l1: 0.115353\n",
      "[1600]\ttraining's l1: 0.0391109\tvalid_1's l1: 0.114672\n",
      "[1700]\ttraining's l1: 0.0371088\tvalid_1's l1: 0.114067\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1700]\ttraining's l1: 0.0371088\tvalid_1's l1: 0.114067\n",
      "3JHN Fold 2 ####### logMAE: -2.1709703075790174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.3932970243725193"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params = {\n",
    "    '1JHN': 7,\n",
    "    '1JHC': 10,\n",
    "    '2JHH': 9,\n",
    "    '2JHN': 9,\n",
    "    '2JHC': 9,\n",
    "    '3JHH': 9,\n",
    "    '3JHC': 10,\n",
    "    '3JHN': 10\n",
    "}\n",
    "N_FOLDS = 3\n",
    "submission = submission_csv.copy()\n",
    "\n",
    "cv_scores = {}\n",
    "for coupling_type in model_params.keys():\n",
    "    cv_score = train_and_predict_for_one_coupling_type(\n",
    "        coupling_type, submission, n_atoms=model_params[coupling_type], n_folds=N_FOLDS)\n",
    "    cv_scores[coupling_type] = cv_score\n",
    "\n",
    "pd.DataFrame({'type': list(cv_scores.keys()), 'cv_score': list(cv_scores.values())})\n",
    "np.mean(list(cv_scores.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
